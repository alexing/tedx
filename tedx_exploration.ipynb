{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEDx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import docx\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import unidecode\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text(filename):\n",
    "    doc = docx.Document(filename)\n",
    "    full_text = []\n",
    "    for para in doc.paragraphs:\n",
    "        full_text.append(para.text)\n",
    "    return '\\n'.join(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['file', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'directory' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-82a617a53f60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Copy of \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'directory' is not defined"
     ]
    }
   ],
   "source": [
    "for filename in os.listdir(directory):\n",
    "    if filename.startswith(\"Copy of \"):\n",
    "        os.rename('data/' + filename, 'data/' + filename[8:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docx!\n",
      "data/2016 Hernán Casciari.docx\n",
      "docx!\n",
      "data/2016 Luciano Mellera.docx\n",
      "docx!\n",
      "data/2014 Ariel Lutenberg.docx\n",
      "docx!\n",
      "data/2014 Norberto Jansenson.docx\n",
      "docx!\n",
      "data/2014 Estela de Carlotto.docx\n",
      "docx!\n",
      "data/2015 Alan Robinson.docx\n",
      "docx!\n",
      "data/2016 Eduardo Levy Yeyati.docx\n",
      "docx!\n",
      "data/2015 Valeria Bosio.docx\n",
      "docx!\n",
      "data/2014 Cristina Domenech.docx\n",
      "docx!\n",
      "data/2016 Sebastián Bortnik.docx\n",
      "docx!\n",
      "data/2014 Alejandro Nadra.docx\n",
      "docx!\n",
      "data/2016 Martina Flor.docx\n",
      "docx!\n",
      "data/2016 Filippo Brunelleschi.docx\n",
      "docx!\n",
      "data/2014 Christián Carman.docx\n",
      "docx!\n",
      "data/2016 Marcelo Magnasco.docx\n",
      "docx!\n",
      "data/2014 Magui Choque Vilca.docx\n",
      "docx!\n",
      "data/Diego Pol 2015.docx\n",
      "docx!\n",
      "data/2016 Pere Estupinyà.docx\n",
      "docx!\n",
      "data/2015 Andrés Rieznik.docx\n",
      "docx!\n",
      "data/2014 Eduardo Sáenz de Cabezón.docx\n",
      "docx!\n",
      "data/2016 Lucía Gagliardini.docx\n",
      "docx!\n",
      "data/2015 Daniel Molina.docx\n",
      "docx!\n",
      "data/2016 Pablo Meyer Rojas.docx\n",
      "docx!\n",
      "data/2016 Víctor Demaría Pesce.docx\n",
      "docx!\n",
      "data/Fernando Salem 2016.docx\n",
      "docx!\n",
      "data/2016 Diego Gutiérrez Zaldívar.docx\n",
      "docx!\n",
      "data/2015 Aristarco.docx\n",
      "docx!\n",
      "data/2016 César Silveyra.docx\n",
      "docx!\n",
      "data/2014 Luis von Ahn.docx\n",
      "docx!\n",
      "data/2015 Luciano Sposato.docx\n",
      "docx!\n",
      "data/2014  Daniel Cerezo.docx\n",
      "docx!\n",
      "data/2016 Carina Morillo.docx\n",
      "docx!\n",
      "data/2015 Karina Galperin.docx\n",
      "docx!\n",
      "data/2015 Matías Najún.docx\n",
      "docx!\n",
      "data/Valeria Edelsztein 2015.docx\n",
      "docx!\n",
      "data/2014 Gustavo Grabia.docx\n",
      "docx!\n",
      "data/2015 Ricardo Coler.docx\n",
      "docx!\n",
      "data/2015 Edgardo Mercado.docx\n",
      "docx!\n",
      "data/2014 María Fux_ La vida es movimiento.docx\n",
      "docx!\n",
      "data/2016 Miguel Espeche.docx\n",
      "docx!\n",
      "data/2015 Inés Hercovich.docx\n",
      "docx!\n",
      "data/2016 Diana Wang.docx\n",
      "docx!\n",
      "data/2016 Dora Barrancos.docx\n",
      "docx!\n",
      "data/2016 Silvina Kuperman.docx\n",
      "docx!\n",
      "data/2015 Gonzalo Vilariño.docx\n",
      "docx!\n",
      "data/2015 Sandra Mihanovich.docx\n"
     ]
    }
   ],
   "source": [
    "directory = 'data/'\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".docx\"): \n",
    "        print(\"docx!\")\n",
    "        print(os.path.join(directory, filename))\n",
    "        text = get_text('data/' + filename)\n",
    "        lines = []\n",
    "        pattern = re.compile(\"[0-9]{1,2}:[0-9]{2}\")\n",
    "        for a_line in text.split('\\n'):\n",
    "            if not pattern.match(a_line):\n",
    "                lines.append(a_line)\n",
    "        text = \"\\n\".join(lines)\n",
    "    elif filename.endswith('.txt'):\n",
    "        # print(\"txt!\")\n",
    "        # print(os.path.join(directory, filename)) \n",
    "        with open('data/' + filename, 'r') as f:\n",
    "            text = f.read()\n",
    "            first_line = text.split('\\n')[0]\n",
    "            second_line = text.split('\\n')[1]\n",
    "            if first_line.lower().startswith(\"traductor\") and second_line.lower().startswith(\"revisor\"):\n",
    "                text = \"\\n\".join(text.split('\\n')[2:])\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    data = pd.DataFrame({\"file\": [filename], \"text\": [text]})\n",
    "    df = df.append(data, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.replace(\"\\n\", ' ')\n",
    "df['words'] = df.text.str.strip().str.split('[\\W_]+')\n",
    "rows = list()\n",
    "for row in df[['words']].iterrows():\n",
    "    r = row[1]\n",
    "    for word in r.words:\n",
    "        rows.append((word))\n",
    "\n",
    "words = pd.DataFrame(rows, columns=['word'])\n",
    "words = words[words.word.str.len() > 0]\n",
    "words['word'] = words.word.str.lower()\n",
    "counts = words.word.value_counts().to_frame().rename(columns={'word':'count_per_word'})\n",
    "\n",
    "stopwords = stopwords.words('spanish')\n",
    "for a_stopword in stopwords:\n",
    "    if a_stopword in counts.index:\n",
    "        counts = counts.drop(a_stopword)\n",
    "        \n",
    "drop_list = ['aplausos', 'si']\n",
    "for a_word in counts.index:\n",
    "    if unidecode.unidecode(a_word) in stopwords:\n",
    "        drop_list.append(a_word)\n",
    "\n",
    "counts = counts.drop(drop_list)\n",
    "top_20 = counts.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax = sns.barplot(x=\"count_per_word\", y=top_20.index, data=top_20, palette=sns.light_palette(\"green\", n_colors=20, reverse=True))\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('Cantidad de apariciones', fontsize=20)\n",
    "plt.title('Las 20 palabras más frecuentes', fontsize=25)\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(20) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(20)\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    ax.text(width + 3  ,\n",
    "            p.get_y() + p.get_height()/1.4,\n",
    "            \"%d\" % width,\n",
    "            ha=\"center\", fontsize=15)\n",
    "sns.despine()\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "head = counts.head(200)\n",
    "to_plot = list(zip(head.index, head['count_per_word']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wordcloud_from_list(a_list, title=None):\n",
    "    if not title:\n",
    "        title = \"img_%d.jpg\" % math.random.uniform(1, 12321)\n",
    "    freqs_by_words = {}\n",
    "    for a_topic_term in a_list:\n",
    "        an_actual_word = a_topic_term[0]\n",
    "        freqs_by_words[an_actual_word] = a_topic_term[1]\n",
    "\n",
    "    wc = WordCloud(background_color=\"white\", max_words=2000, max_font_size=100,)\n",
    "    # generate word cloud\n",
    "    wc.generate_from_frequencies(freqs_by_words)\n",
    "\n",
    "    #show\n",
    "    plt.figure(figsize=(15,10))\n",
    "    plt.imshow(wc, cmap=plt.cm.gray, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_wordcloud_from_list(to_plot, \"wordcloud\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopset = set(stopwords + drop_list)\n",
    "TED_TALK_DURATION = 20 * 60 # SECONDS. (20 min each ted talk)\n",
    "df['tokens'] = pd.Series(dtype=object)\n",
    "for index, row in df.iterrows():\n",
    "    tokens = word_tokenize(row['text'])\n",
    "    tokens_wo_stopwords = [word for word in tokens if not word in stopset]\n",
    "    df.at[index, 'tokens'] = tokens_wo_stopwords\n",
    "    df.at[index, 'le_d'] = ( len(tokens_wo_stopwords) / len(tokens) ) * 100\n",
    "    df.at[index, 'ly_d'] = len(tokens) / TED_TALK_DURATION\n",
    "    df.at[index, 'n_words'] = len(tokens)\n",
    "    df.at[index, 'n_words_no_rep'] = len(list(set(tokens)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_speakers = df.sort_values(\"ly_d\", ascending=False)[:5]\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax = sns.barplot(x=\"ly_d\", y='file', data=faster_speakers, palette=sns.light_palette(\"red\", n_colors=5, reverse=True))\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('Densidad lírica (palabras/seg)', fontsize=20)\n",
    "plt.title('Las 5 oradores más rápidos', fontsize=25)\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(20) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(20)\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    ax.text(width + .2  ,\n",
    "            p.get_y() + p.get_height()/2.,\n",
    "            \"%.02f\" % width,\n",
    "            ha=\"center\", fontsize=15)\n",
    "sns.despine()\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "more_vocab = df.sort_values(\"n_words\", ascending=False)[:5]\n",
    "more_vocab = more_vocab[['file', 'n_words', 'n_words_no_rep']]\n",
    "more_vocab.columns = ['file', 'Cantidad de palabras', 'Cantidad de palabras únicas']\n",
    "\n",
    "more_vocab = (\n",
    "    more_vocab.set_index('file')\n",
    "      .stack()  # un-pivots the data \n",
    "      .reset_index()  # moves all data out of the index\n",
    "      .rename(columns={'level_1': 'Variable', 0: 'Value'})\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "ax = sns.barplot(x=\"Value\", y='file', hue='Variable', data=more_vocab, palette=\"Set3\")\n",
    "plt.ylabel(\"\")\n",
    "plt.xlabel('Cantidad de palabras', fontsize=20)\n",
    "plt.title('Las 5 oradores con vocabulario más extenso', fontsize=25)\n",
    "for tick in ax.xaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(20) \n",
    "for tick in ax.yaxis.get_major_ticks():\n",
    "    tick.label.set_fontsize(20)\n",
    "for p in ax.patches:\n",
    "    width = p.get_width()\n",
    "    ax.text(width + 110  ,\n",
    "            p.get_y() + p.get_height()/2.,\n",
    "            \"%d\" % width,\n",
    "            ha=\"center\", fontsize=15)\n",
    "ax.legend(prop={'size': 20})\n",
    "\n",
    "sns.despine()\n",
    "plt.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
