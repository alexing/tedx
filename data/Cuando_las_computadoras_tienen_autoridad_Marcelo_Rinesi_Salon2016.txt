Le estamos dando cada día
más poder político a las computadoras,
en un sentido muy específico:
Cada vez más, cada vez más decisiones,
cada vez más importantes,
las toman computadoras sin que
sean vetadas por seres humanos.
Ya sea, mostrarle una chica de cinco años
publicidad para bajar de peso
o decir que una persona es
un riesgo a la seguridad.
Y eso tiene implicancias,
tiene consecuencias
en la vida diaria de esas personas.
Pueden ser desde "No puedo viajar,
no consigo visa"
hasta, y este es un caso real,
que un dron te tire una bomba
porque un algoritmo del Pentágono
no distingue entre un terrorista
y un periodista que investiga terrorismo.
Lo nuevo es que no se está codificando
como una burocracia
reglas que fueron creadas, definidas
y consensuadas -- bien o mal --
por seres humanos.
Tenemos reglas extraídas estadísticamente
para cumplir objetivos
que ponen los humanos pero de formas
que los humanos no entienden.
Un ingeniero, un científico de datos,
puede explicar cada paso del proceso.
Lo construyó, no es magia,
no es mitología.
Pero para la persona cuya autoridad
está siendo delegada
-- la persona que consideramos
con "poder" --
y la persona que sufre ese poder,
que está bajo esa autoridad,
no es entendible, es opaco.
Esto viola un acuerdo tan tácito,
tan implícito en las sociedades,
que nunca lo pensamos:
que el que tiene autoridad
sobre mí es una persona.
Sus motivaciones, su forma de pensar,
las puedo compartir o no, lo puedo 
odiar, pero lo entiendo, es un humano.
Incluso cuando lidiamos 
con algo como un mercado,
que sabemos conscientemente
que es gigantesco, complejísimo,
solamente un porcentaje pequeño
está compuesto de humanos,
decimos: el mercado "tiene miedo",
el mercado "esperaba cierta medida".
Es una falacia, es una ilusión.
Los mercados no tienen sentimientos.
Hace no mucho, un prototipo de 
reconocimiento de imágenes de Google,
confundió en una foto a dos
personas negras con gorilas.
Eso no es racismo. El racismo es una
tontería específicamente de los humanos.
Pero, las personas se sintieron
atacadas, humanamente.
Imaginen si ese programa
no fuera un prototipo,
sino que es parte
del software del Estado.
Cada vez más decisiones
del Estado son tomadas,
segundo a segundo, por computadoras.
Cada vez más lo que nosotros
percibimos, aprendemos,
lo que se invierte
en seguridad, educación,
no todavía hasta dentro de 10 a 15 años,
las decisiones más macro.
Pero el segundo a segundo de cómo
interactuamos con el mundo físico,
desde nuestros relojes
-- los que tengan relojes todavía --
hasta las ciudades, desde la
seguridad social, hasta el Ejército,
son decisiones que las toman
pequeñas mentes muy especializadas,
que no son humanas.
Generalmente, y esto es
por razones comerciales,
las decisiones son las que esperábamos.
Comercialmente no tiene sentido un
programa que te sorprende constantemente.
Eso nos da la sensación de
seguridad falsa de que entendemos
y cada tanto, como el programa de Google,
hacen algo que estadísticamente,
matemáticamente,
es completamente lógico y,
sin embargo, nos parece inhumano.
Porque nos habíamos olvidado de que,
de hecho, no son humanos.
Esto no quiere decir que
las decisiones sean malas.
Al contrario, uno puede
esperar que cualquier cosa
que uno pueda entender
suficientemente bien
la computadora la va a hacer
mejor que un humano.
Eso es casi la definición de
entender suficientemente bien.
Pero lo que estamos haciendo es un
experimento único en la historia humana.
Estamos construyendo
por primera vez una sociedad
en la cual parte del poder
del día a día no lo tienen humanos.
Lo tienen mentes que no son humanas;
que nosotros construimos, les damos poder,
y después interactuamos con ellas
y no sabemos qué pasa.
La experiencia política, cultural,
psicológica de vivir en un mundo así
no puedo decir si es buena o mala,
no puedo decir si nos va a aterrorizar,
si va a ser un mundo
de espíritus que no entendemos
o va a ser un mundo a nuestro servicio.
No depende de la tecnología,
es una decisión política
que no podemos evadir,
que es tal vez una de las dos o tres
decisiones más importantes
de nuestra generación.
Estamos haciendo un mundo
no solo de personas.
Como es ese mundo, nos toca
decidir en 10 o 20 años.
Muchas gracias.
(Aplausos)
